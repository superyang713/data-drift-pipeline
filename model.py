"""This script demostrate why data drift monitorin is important.

From the plot generated by the script, the model performance degrades over time.

"""
import os
from pathlib import Path
import datetime as dt

import pandas as pd
import matplotlib.pyplot as plt

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error

from google.cloud import storage, bigquery


PROJECT = "mightyhive-data-science-poc"
TABLE_ID = f"{PROJECT}.data_drift_demo.bike_sharing"
SERVICE_PATH = Path.home().joinpath(".ssh", "mightyhive.json")


def main():
    regressor = train()
    # mae on the training data
    n_batch = 20
    maes = [
        calculate_mae_nth_four_weeks_data(TABLE_ID, i, regressor)
        for i in range(n_batch)
    ]
    plt.plot(range(n_batch), maes)
    plt.scatter(range(n_batch), maes)
    plt.show()


def load_data_from_bigquery(table_id, start=None, end=None):
    bq_client = bigquery.Client().from_service_account_json(SERVICE_PATH)
    query = (
        f"""
        SELECT
          count,
          temp,
          atemp,
          humidity,
          windspeed,
          season,
          holiday,
          workingday,
          EXTRACT(DAYOFWEEK FROM datetime) AS weekday,
          EXTRACT(HOUR FROM datetime) AS hour,
        FROM
          `{table_id}`
        """
    )

    if start and end:
        query = (
            f"""
            {query}
            WHERE DATE(datetime) BETWEEN "{start}" and "{end}"
            """
        )
    df= bq_client.query(query).result().to_dataframe()
    return df


def train():
    start = "2011-01-01"
    end = "2011-01-28"
    df = load_data_from_bigquery(TABLE_ID, start, end)
    X = df.drop(["count"], axis=1)
    y = df["count"]
    # train regressor model
    regressor = RandomForestRegressor(random_state=0, n_estimators=50)
    regressor.fit(X, y)
    return regressor


def load_nth_four_weeks_data(table_id, n):
    """
    n: the nth interval. When n = 0, it is the training data.
    """
    interval = dt.timedelta(days=28)
    start = dt.date(2011, 1, 1) + interval * n
    end = start + interval
    df = load_data_from_bigquery(table_id, start, end)
    return df


def calculate_mae_nth_four_weeks_data(table_id, n, model):
    print(f"Calculating batch {n}")
    df = load_nth_four_weeks_data(table_id, n)
    X = df.drop(["count"], axis=1)
    y = df["count"]
    y_pred = model.predict(X)
    mae = mean_absolute_error(y, y_pred)
    return mae


if __name__ == '__main__':
    main()
